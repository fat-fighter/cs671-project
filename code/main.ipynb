{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS671 - k-Match-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from includes import config\n",
    "from includes.utils import is_outlier\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams = mpl.rc_params_from_file(\"includes/matplotlibrc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Clustering data based on tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Choosing the number of Clusters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "data = []\n",
    "with open(\"data/squad/train.context\") as f:\n",
    "    for line in f:\n",
    "        data.append(line.strip())\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=config.max_df,\n",
    "    min_df=config.min_df,\n",
    "    max_features=config.max_tfidf_vocab,\n",
    "    stop_words='english',\n",
    "    use_idf=True\n",
    ")\n",
    "X = vectorizer.fit_transform(data)\n",
    "\n",
    "X_tr = X[:7 * X.shape[0] / 10]\n",
    "X_ts = X[7 * X.shape[0] / 10:]\n",
    "\n",
    "s = 35\n",
    "e = 36\n",
    "\n",
    "km = [\n",
    "    MiniBatchKMeans(\n",
    "        n_init=20,\n",
    "        n_clusters=k,\n",
    "        batch_size=2500,\n",
    "        max_iter=10000,\n",
    "        init='k-means++'\n",
    "    ) for k in range(s, e)\n",
    "]\n",
    "\n",
    "for k in range(0, e - s):\n",
    "    km[k].fit(X_tr)\n",
    "\n",
    "inertias = [km[k].inertia_ for k in range(0, e - s)]\n",
    "plt.plot(range(s, e), inertias)\n",
    "\n",
    "if not os.path.exists(\"plots/\"):\n",
    "    os.makedirs(\"plots/\")\n",
    "plt.savefig()\n",
    "\n",
    "for k in range(0, e - s):\n",
    "    cluster_labels = km[k].predict(X_ts)\n",
    "    silhouette_avg = silhouette_score(X_ts, cluster_labels)\n",
    "    print(\"n_clusters =\", k + s, \", silhouette_score =\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Clustering data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Clustering on the basis of Tf-IDF Representation of\n",
    "## the questions or context as per the value if the\n",
    "## parameter 'clustering' in 'includes/config'.\n",
    "\n",
    "## This idea was dropped later\n",
    "\n",
    "cd = np.concatenate([data, val_data])\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=config.max_df,\n",
    "    min_df=config.min_df,\n",
    "    max_features=config.max_tfidf_vocab,\n",
    "    stop_words='english',\n",
    "    use_idf=True,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "X = vectorizer.fit_transform(cd)\n",
    "\n",
    "X_val = X[len(data):]\n",
    "X = X[:len(data)]\n",
    "\n",
    "km = KMeans(\n",
    "    n_init=config.kmeans_n_init,\n",
    "    max_iter=config.kmeans_max_iter,\n",
    "    n_clusters=config.n_clusters,\n",
    "    init='k-means++',\n",
    "    n_jobs=-1,\n",
    "    algorithm=\"full\"\n",
    ")\n",
    "\n",
    "km.fit(X)\n",
    "\n",
    "labels = np.array([str(label) for label in km.predict(X)])\n",
    "with open(\"data/squad/train.labels\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(labels))\n",
    "\n",
    "labels_val = np.array([str(label) for label in km.predict(X_val)])\n",
    "with open(\"data/squad/val.labels\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(labels))\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "ax1.hist(labels, bins=config.n_clusters, rwidth=0.7)\n",
    "ax2.hist(labels_val, bins=config.n_clusters, rwidth=0.7)\n",
    "plt.show()\n",
    "\n",
    "labels = np.array([int(label) for label in labels])\n",
    "labels_val = np.array([int(label) for label in labels_val])\n",
    "\n",
    "_X = X_val\n",
    "labels = km.predict(_X)\n",
    "_X = _X.toarray()\n",
    "\n",
    "clf = LinearDiscriminantAnalysis(n_components=2)\n",
    "clf.fit(_X, labels)\n",
    "\n",
    "tr_X = clf.transform(_X)\n",
    "\n",
    "filter = ~is_outlier(tr_X)\n",
    "tr_X = tr_X[filter]\n",
    "labels = labels[filter]\n",
    "\n",
    "for label in range(0, config.n_clusters):\n",
    "    label_X = tr_X[labels == label]\n",
    "    plt.scatter(label_X[:, 0], label_X[:, 1], s=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Clustering based on question type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = ''.join([i if ord(i) < 128 else ' ' for i in text.strip()])\n",
    "    tokens = nltk.wordpunct_tokenize(text)\n",
    "    text = nltk.Text(tokens)\n",
    "    \n",
    "    return [w.lower() for w in text if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"data/squad/train.questions\") as f:\n",
    "    for line in f:\n",
    "        data.append(clean_text(line.lower()))\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_data = []\n",
    "with open(\"data/squad/val.questions\") as f:\n",
    "    for line in f:\n",
    "        val_data.append(clean_text(line))\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_label(line):\n",
    "    bow = np.zeros(len(line))\n",
    "    words = {\"what\": 0, \"where\": 1, \"who\": 2, \"how\": 3, \"which\": 4}\n",
    "    for word in words:\n",
    "        bow[line == word] = 1\n",
    "    \n",
    "    try:\n",
    "        _label = words[line[np.where(bow == 1)[0][0]]]\n",
    "        return _label\n",
    "    except Exception as e:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = np.array([get_label(np.array(line)) for line in data])\n",
    "labels_val = np.array([get_label(np.array(line)) for line in val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/squad/train.labels\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(\n",
    "        [str(label) for label in labels]\n",
    "    ))\n",
    "\n",
    "with open(\"data/squad/val.labels\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(\n",
    "        [str(label) for label in labels_val]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "ax1.hist(labels, bins=config.n_clusters, rwidth=0.7)\n",
    "ax2.hist(labels_val, bins=config.n_clusters, rwidth=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match-LSTM for Machine Comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from includes import config\n",
    "from includes.utils import squad_dataset, evaluate\n",
    "\n",
    "from graph import Graph\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "words_embedding = np.load(config.embed_path)[\"glove\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    config.encoding_size\n",
    ")\n",
    "decoder = Decoder(\n",
    "    config.encoding_size,\n",
    "    config.n_clusters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "graph = Graph(\n",
    "    words_embedding,\n",
    "    encoder,\n",
    "    decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "init = graph.init_model(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data = squad_dataset(\n",
    "    config.questions_train,\n",
    "    config.contexts_train,\n",
    "    config.answers_train,\n",
    "    config.labels_train,\n",
    "    root=root_dir + \"/\",\n",
    "    batch_size=config.batch_size\n",
    ")\n",
    "\n",
    "val_data = squad_dataset(\n",
    "    config.questions_val,\n",
    "    config.contexts_val,\n",
    "    config.answers_val,\n",
    "    config.labels_val,\n",
    "    root=root_dir + \"/\",\n",
    "    batch_size=config.val_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_score(epoch, score):\n",
    "    print \"\\nepoch: %d, f1: %.4f, em: %.4f, em@1: %.4f, em@2: %.4f\\n\" % (\n",
    "        epoch, score[1], score[0][0], score[0][1][0], score[0][1][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "if os.path.exists(config.loss_path):\n",
    "    losses = list(np.load(config.loss_path))\n",
    "\n",
    "scores = []\n",
    "if os.path.exists(config.scores_path):\n",
    "    scores = list(np.load(config.scores_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_em = np.max([score[0][1] for score in scores]) or 0\n",
    "\n",
    "if not init:\n",
    "    scores.append(\n",
    "        evaluate(graph, sess, val_data, \"evaluating ... epoch: 0\")\n",
    "    )\n",
    "    print_score(0, scores[-1])\n",
    "else:\n",
    "    score = evaluate(graph, sess, val_data, \"evaluating ... epoch: 0\")\n",
    "    print_score(0, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(config.num_epochs)[:1]:\n",
    "\n",
    "    losses.append(graph.run_epoch(\n",
    "        train_data, epoch, sess, max_batch_epochs=-1)\n",
    "    )\n",
    "\n",
    "    scores.append(\n",
    "        evaluate(graph, sess, val_data, \"evaluating ... epoch: %d\" % (epoch + 1))\n",
    "    )\n",
    "    print_score(epoch + 1, scores[-1])\n",
    "    \n",
    "    if scores[-1][0][0] >= best_em:\n",
    "        graph.save_model(sess)\n",
    "        best_em = scores[-1][0][0]\n",
    "\n",
    "        np.save(\"data/plots/loss.npy\", np.array(losses))\n",
    "        np.save(\"data/plots/scores.npy\", np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams = mpl.rc_params_from_file(\"includes/matplotlibrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = [(\"match-lstm\", \"MatchLSTM\"), (\"k-match-lstm\", \"K-MatchLSTM\"), (\"weighted-k-match-lstm\", \"Weighted K-MatchLSTM\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"plots/\"):\n",
    "    os.makedirs(\"plots/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "losses = np.load(\"data/plots.k-match-lstm/loss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    losses = np.load(\"data/plots.\" + model[0] + \"/loss.npy\")\n",
    "    \n",
    "    size = np.prod(losses.shape)\n",
    "    losses = losses.reshape(size)[:size / 40 * 40]\n",
    "    \n",
    "    plt.plot(np.array(losses).reshape(size / 40, 40).mean(axis = 1))\n",
    "    \n",
    "    plt.title(\"Model: %s\" % model[1])\n",
    "    \n",
    "    plt.xlabel(\"Number of mini-batch iterations (x40)\")\n",
    "    plt.savefig(\"plots/loss.\" + model[0] + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    scores = np.load(\"data/plots.\" + model[0] + \"/scores.npy\")\n",
    "    \n",
    "    plt.plot([e[0][0] for e in scores], label=\"em\")\n",
    "    plt.plot([e[0][1][0] for e in scores], label=\"em1\")\n",
    "    plt.plot([e[0][1][1] for e in scores], label=\"em2\")\n",
    "    plt.plot([e[1] for e in scores], label=\"f1\")\n",
    "    \n",
    "    plt.title(\"Model: %s\" % model[1])\n",
    "    \n",
    "    plt.xlabel(\"Number of Epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(\"plots/accuracy.\" + model[0] + \".png\")\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    scores = np.load(\"data/plots.\" + model[0] + \"/scores.npy\")\n",
    "    \n",
    "    plt.plot([e[0][0] for e in scores], label=model[1])\n",
    "    \n",
    "plt.title(\"EM Comparision over Epochs\")\n",
    "\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"EM Score\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"plots/comparision.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fat-fighter/Softwares/conda/envs/machine-learning/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from includes import config\n",
    "from includes.utils import squad_dataset, evaluate, initialize_vocab\n",
    "\n",
    "from graph import Graph\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embedding = np.load(config.embed_path)[\"glove\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    config.encoding_size\n",
    ")\n",
    "decoder = Decoder(\n",
    "    config.encoding_size,\n",
    "    config.n_clusters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From includes/mlstm.py:16: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "\n",
      "Using Adam Optimizer with lr: 0.002000, decay_steps: 1000, decay_rate: 0.920000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = Graph(\n",
    "    words_embedding,\n",
    "    encoder,\n",
    "    decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing model from model/weighted-k-match-lstm/trained_model.chk ... \n",
      "INFO:tensorflow:Restoring parameters from model/weighted-k-match-lstm/trained_model.chk\n",
      "Initialized model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init = graph.init_model(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = ''.join([i if ord(i) < 128 else ' ' for i in text.strip()])\n",
    "    tokens = nltk.wordpunct_tokenize(text)\n",
    "    text = nltk.Text(tokens)\n",
    "    \n",
    "    return [w.lower() for w in text if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(line):\n",
    "    bow = np.zeros(len(line))\n",
    "    words = {\"what\": 0, \"where\": 1, \"who\": 2, \"how\": 3, \"which\": 4}\n",
    "    for word in words:\n",
    "        bow[line == word] = 1\n",
    "    \n",
    "    try:\n",
    "        _label = words[line[np.where(bow == 1)[0][0]]]\n",
    "        return _label\n",
    "    except Exception as e:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, rev_vocab = initialize_vocab(config.vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(context, question, graph, sess):\n",
    "    context_ids = []\n",
    "    for word in context.split():\n",
    "        if word in vocab:\n",
    "            context_ids.append(vocab[word])\n",
    "        else:\n",
    "            context_ids.append(2)\n",
    "\n",
    "    question_ids = []\n",
    "    for word in question.split():\n",
    "        if word in vocab:\n",
    "            question_ids.append(vocab[word])\n",
    "        else:\n",
    "            question_ids.append(2)\n",
    "\n",
    "    label = get_label(np.array(clean_text(question)))\n",
    "\n",
    "    answer = graph.predict(sess, np.array([[[question_ids, context_ids, [0, 0], label]]]), msg=None)[0][0].astype(int)\n",
    "    \n",
    "    return \" \".join(context.split()[answer[0]:answer[1] + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Michael was a Norman who followed King William I to England, and became Sheriff of Worcestershire and a royal official under him and Kings William II and Henry I. He was a native of Normandy and moved to England shortly after the Norman conquest of England in 1066, and was appointed sheriff in about 1069. Little is known of his family in Normandy, who were not prominent. Although Urse's lord in Normandy was present at the Battle of Hastings, there is no evidence that Urse took part in the invasion of England in 1066. Urse built the earliest form of Worcester Castle in Worcester, which encroached on the cathedral cemetery there, earning him a curse from the Archbishop of York. Urse helped to put down a rebellion against King William I in 1075, and quarrelled with the Church in his county over the jurisdiction of the sheriffs. He continued in the service of William's sons after the king's death, and was appointed constable under William II and marshal under Henry I.\"\n",
    "questions = [\"Who was Michael?\", \"Who did Michael follow?\", \"Who became the Sheriff?\", \"When was he appointed Sheriff?\", \"What did Urse build?\", \"Where did Urse build the earliest form of Worcester Castle?\", \"Where did Michael move to?\", \"Who helped put down a rebellion against King William I\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context   :  Michael was a Norman who followed King William I to England, and became Sheriff of Worcestershire and a royal official under him and Kings William II and Henry I. He was a native of Normandy and moved to England shortly after the Norman conquest of England in 1066, and was appointed sheriff in about 1069. Little is known of his family in Normandy, who were not prominent. Although Urse's lord in Normandy was present at the Battle of Hastings, there is no evidence that Urse took part in the invasion of England in 1066. Urse built the earliest form of Worcester Castle in Worcester, which encroached on the cathedral cemetery there, earning him a curse from the Archbishop of York. Urse helped to put down a rebellion against King William I in 1075, and quarrelled with the Church in his county over the jurisdiction of the sheriffs. He continued in the service of William's sons after the king's death, and was appointed constable under William II and marshal under Henry I.\n",
      "\n",
      "Question  :  Who was Michael?\n",
      "Answer    :  Michael\n",
      "Question  :  Who did Michael follow?\n",
      "Answer    :  England,\n",
      "Question  :  Who became the Sheriff?\n",
      "Answer    :  Michael\n",
      "Question  :  When was he appointed Sheriff?\n",
      "Answer    :  after the Norman conquest of England in 1066,\n",
      "Question  :  What did Urse build?\n",
      "Answer    :  Michael\n",
      "Question  :  Where did Urse build the earliest form of Worcester Castle?\n",
      "Answer    :  Worcester Castle\n",
      "Question  :  Where did Michael move to?\n",
      "Answer    :  England\n",
      "Question  :  Who helped put down a rebellion against King William I\n",
      "Answer    :  York. Urse\n"
     ]
    }
   ],
   "source": [
    "print \"Context   :  %s\" % context\n",
    "print\n",
    "for i in range(len(questions)):\n",
    "    print \"Question  :  %s\" % questions[i]\n",
    "    print \"Answer    :  %s\" % get_answer(context, questions[i], graph, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = squad_dataset(\n",
    "    \"data/squad/val.questions\",\n",
    "    \"data/squad/val.contexts\",\n",
    "    \"data/squad/val.answers\",\n",
    "    config.labels_val,\n",
    "    root=root_dir + \"/\",\n",
    "    batch_size=1,\n",
    "    split=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context   :  From early Christian times , hunting has been forbidden to Roman Catholic Church clerics . Thus the Corpus Juris Canonici ( C. ii , X , De cleric . venat . ) says , \" We forbid to all servants of God hunting and expeditions through the woods with hounds ; and we also forbid them to keep hawks or falcons . \" The Fourth Council of the Lateran , held under Pope Innocent III , decreed ( canon xv ) : \" We interdict hunting or hawking to all clerics . \" The decree of the Council of Trent is worded more mildly : \" Let clerics abstain from illicit hunting and hawking \" ( Sess . XXIV , De reform. , c. xii ) , which seems to imply that not all hunting is illicit , and canonists generally make a distinction declaring noisy ( clamorosa ) hunting unlawful , but not quiet ( quieta ) hunting .\n",
      "\n",
      "\n",
      "Question  :  What forbid hunting in the woods with hounds and keeping hawks or falcons ?\n",
      "\n",
      "Answer    :  Let clerics\n",
      "Ground    :  Corpus Juris Canonici\n",
      "\n",
      "\n",
      "Context   :  The Bronx street grid is irregular . Like the northernmost part of upper Manhattan , the West Bronx 's hilly terrain leaves a relatively free-style street grid . Much of the West Bronx 's street numbering carries over from upper Manhattan , but does not match it exactly ; East 132nd Street is the lowest numbered street in the Bronx . This dates from the mid-19th century when the southwestern area of Westchester County west of the Bronx River , was incorporated into New York City and known as the Northside .\n",
      "\n",
      "\n",
      "Question  :  What was the Bronx called in the mid-19th century ?\n",
      "\n",
      "Answer    :  Northside\n",
      "Ground    :  the Northside\n",
      "\n",
      "\n",
      "Context   :  Renaissance humanism was an activity of cultural and educational reform engaged in by civic and ecclesiastical chancellors , book collectors , educators , and writers , who by the late fifteenth century began to be referred to as umanisti â€“ \" humanists \" . It developed during the fourteenth and the beginning of the fifteenth centuries , and was a response to the challenge of scholastic university education , which was then dominated by Aristotelian philosophy and logic . Scholasticism focused on preparing men to be doctors , lawyers or professional theologians , and was taught from approved textbooks in logic , natural philosophy , medicine , law and theology . There were important centres of humanism at Florence , Naples , Rome , Venice , Mantua , Ferrara , and Urbino .\n",
      "\n",
      "\n",
      "Question  :  Where was one main concentration of Humanism ?\n",
      "\n",
      "Answer    :  Florence , Naples , Rome , Venice , Mantua , Ferrara , and Urbino\n",
      "Ground    :  Naples\n",
      "\n",
      "\n",
      "Context   :  The Bronx is named after Jonas Bronck who created the first settlement as part of the New Netherland colony in 1639 . The native Lenape were displaced after 1643 by settlers . In the 19th and 20th centuries , the Bronx received many immigrant groups as it was transformed into an urban community , first from various European countries ( particularly Ireland , Germany and Italy ) and later from the Caribbean region ( particularly Puerto Rico , Jamaica and the Dominican Republic ) , as well as African American migrants from the American South . This cultural mix has made the Bronx a wellspring of both Latin music and hip hop .\n",
      "\n",
      "\n",
      "Question  :  What did Bronck do ?\n",
      "\n",
      "Answer    :  who created the first settlement as part of the New Netherland colony\n",
      "Ground    :  created the first settlement as part of the New Netherland colony\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in val_data:\n",
    "    if raw_input() != \"-1\":\n",
    "        q, c, a, _ = data[0]\n",
    "        print \"Context   :  %s\" % c\n",
    "        print\n",
    "        print \"Question  :  %s\" % q\n",
    "        print \"Answer    :  %s\" % get_answer(c, q, graph, sess)\n",
    "        print \"Ground    :  %s\" % a\n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (Machine Learning)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
